---
layout: post
title: "Animation Compression Library: Release 0.4.0"
---
This marks the fourth release of ACL. It contains a lot of [good stuff](https://github.com/nfrechette/acl/blob/develop/CHANGELOG.md) but most notable is the addition of [segmenting support](http://nfrechette.github.io/2016/11/10/anim_compression_uniform_segmenting/). I have not had the chance to play with the settings much yet but using segments of **16** key frames reduces the memory footprint by about **13%** with variable quantization under uniform sampling. Adding range reduction on top of it, per segment, further reduces the memory footprint by another **10%**. This is very significant.

Some optimizations also made it in to the compression time, reducing it by **4.3x** with no compromise to quality.

You can see the latest numbers [here](https://github.com/nfrechette/acl/blob/develop/docs/acl_vs_ue4_vs_unity.md) as well as how they compare against the previous releases [here](https://github.com/nfrechette/acl/blob/develop/docs/performance_history.md).

The results in themselves are quite good but when compared to Unreal 4, they are very impressive.

ACL 0.4 compresses [CMU](http://mocap.cs.cmu.edu/) down to **82.25mb** in **50 minutes** single-threaded and **5 minutes** multi-threaded with a maximum error of **0.0635cm**. Unreal 4.15 compresses it down to **107.94mb** in **3 hours and 54 minutes** single-threaded with a maximum error of **0.0850cm**. Importantly, this is achieved with no compromise to decompression speed (although not yet measured, is estimated to be faster with ACL).

// ACL 0.4 VS UE 4.15 error and ratio

As I have previously mentioned, Unreal 4 has a very solid error metric and good implementations of common animation compression techniques. It most definitely is well representative of the state of animation compression in game engines everywhere.

The biggest source of error in both ACL and Unreal 4 comes from the usage of the simple quaternion format consisting of [dropping the **W** component](http://nfrechette.github.io/2016/10/27/anim_compression_data/) to later reconstruct it at runtime. As it turns out, this is terribly inaccurate when that component is very small. Better formats exist and will be implemented later.

## How accurate are we?

Over the years, I've read my fair share of animation compression papers and posts. And while they all measure the error differently the one thing they have in common is that they only talk about the worst error within a clip (or whole set of clips). [As I have previously mentioned](http://nfrechette.github.io/2016/11/01/anim_compression_accuracy/), how you measure the error is very important and must be done carefully but that is not all. Using the worst error within a given clip does not give a full picture. What about the other bones in the clip? What about the other key frames? Do I have a single bone on a single key frame that violates my threshold or do I have many?

In order to get a full and clear picture, I dumped the error of every bone at every key frame in the original clips. This represents over **37 million** samples.

// Insert image ACL 0.4 VS UE 4.15 @ 1.0 exhaustive error

## Is the comparison fair?

Unreal 4 and ACL both use somewhat similar error metrics but the default settings are quite different. Is the comparison fair? To generate the above results, the default error threshold used in Unreal was **1.0cm**. This value is very very high; so high in fact that it would not be expected to be used in production. As such, I extracted the data again with thresholds of **0.1cm** (which would be suitable for production due to the fact that the algorithms aren't as aggressive as ACL) and **0.01cm** in order to see how the data looks if we try to match the same quality guarantee.

// Insert image ACL 0.4 VS UE 4.15 @ 1.0, 0.1, 0.01 ratio

// Insert image ACL 0.4 VS UE 4.15 @ 1.0, 0.1, 0.01 error

// Insert image ACL 0.4 VS UE 4.15 @ 1.0, 0.1, 0.01 exhaustive error


